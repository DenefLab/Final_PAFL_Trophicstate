---
title: "Re-run of Mothur for reproducibility and FWDB Analysis"
author: "Marian L. Schmidt"
date: "Nov. 3rd, 2015"
output: html_document
---


```{r knitr_global_options, eval = TRUE, echo = FALSE}
# Set the global options
knitr::opts_chunk$set(echo=FALSE, eval = TRUE, fig.width=6, fig.height=5, fig.align = 'center', warning=FALSE, message=FALSE)
# Set the seed
## runif(1, 0, 10^8) # Run this command once and plug it into the set.seed() function
set.seed(15879966)
```

```{r load libraries and packages}
# Load packages
necessary_packages <-  c("phyloseq", "ggplot2", "ape", "vegan", "plyr", "scales", "grid", "reshape2", "data.table","DESeq2", "dplyr","tidyr", "sciplot","scales", "pgirmess","multcompView", "pander")
# Install the packages that we need
packages <- lapply(necessary_packages, library, character.only = TRUE)

# Make sure to have most updated version of phyloseq
source("https://bioconductor.org/biocLite.R")
biocLite("phyloseq")

### Set the Working Directory  
###  Within the "Final_PAFL_Trophicstate" directory there should be the following 2 sub-directories:
        #   1.  "raw_data":  includes 5 files:  taxonomy table, OTU (shared) table, "metadata", "duplicate_metadata.txt", "AllLakes_depthprofile.csv" 
        #   2.  "alpha_data":  includes 2 files:  "InvSimpson100" and "ObservedRichness100"  (These files are made between lines 261-295 and take ~20 minutes to calculate.  These files are added for reviewer convenience.)
setwd("~/Final_PAFL_Trophicstate/Nov2_Mothur")

### Source written functions in the file Functions_PAFL.R that is housed within the "Final_PAFL_Trophicstate"
source("~/Final_PAFL_Trophicstate/Functions_PAFL.R")
```

```{r data import}
### Data import
#sharedfile = "mothur.normalized.shared"
sharedfile <- "~/Final_PAFL_Trophicstate/Nov2_Mothur/SoMiLakes.files.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.an.unique_list.shared"
taxfile <- "~/Final_PAFL_Trophicstate/Nov2_Mothur/SoMiLakes.files.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.an.unique_list.0.03.cons.taxonomy"
mothurdata <- import_mothur(mothur_shared_file = sharedfile ,mothur_constaxonomy_file = taxfile )

# Change the taxonomy names
tax_table(mothurdata) <- cbind(tax_table(mothurdata),row.names(tax_table(mothurdata)))
colnames(tax_table(mothurdata)) <- c("Kingdom","Phylum","Class","Order","Family","Genus","Species")

# Change some of the sample names to match our metadata sample names
samplenames <- sample_names(mothurdata)
names2 <- gsub("Gull", "GUL", samplenames)
names3 <- gsub("Long", "LON", names2)
sample_names(mothurdata) <- names3

# Import metadata file and merge with mothurdata object
mapfile <- "~/Final_PAFL_Trophicstate/raw_data/metadata"
map <- import_qiime_sample_data(mapfile)
merge <- merge_phyloseq(mothurdata,map)

# lets look at only samples (removing blanks and mock and samples that didn't amplify)
pruned <- prune_taxa(taxa_sums(merge) > 0, merge)
bact_samples <-subset_taxa(pruned, Kingdom == "Bacteria")
#nrow(otu_table(pruned)) - nrow(otu_table(bact_samples))  ## Check how many rows were not bacteria
bact_samples <-subset_taxa(bact_samples, Class != "Chloroplast")
#nrow(otu_table(bact_samples)) - nrow(otu_table(bact_samples2))  # Check how many rows were chloroplasts

#Summary of object
#bact_samples

## Raw Sample read counts
# Histogram of RAW sample read counts
raw_plot <- ggplot(data.frame(sum=sample_sums(bact_samples)),aes(sum)) + ylab("Number of Sequences per Sample") +
  geom_histogram(colour="black",fill="dodgerblue2", binwidth = 750)  + xlab("Total Sequences") +
   ggtitle(expression(atop(bold("Raw Samples"), atop("Binwidth = 750 Sequences", "")))); raw_plot
```

```{r}
################################################################
### Take the average for samples that have a replicate
noscale_merge <- merge_samples_mean(bact_samples, group = "dups", round = "none")  # Here we simply take the Mean between replicate samples 
noscale_merge <- prune_taxa(taxa_sums(noscale_merge) > 0, noscale_merge)

#######  The above functions mess up the metadata - let's fix it!
data_dup <- read.table("~/Final_PAFL_Trophicstate/raw_data/duplicate_metadata.txt", header = TRUE, sep = "\t")
row.names(data_dup) <- data_dup$names
data_dup$quadrant <- factor(data_dup$quadrant,levels = c("Free Epilimnion", "Free Mixed",  "Free Hypolimnion", "Particle Epilimnion", "Particle Mixed", "Particle Hypolimnion"))
data_dup <- sample_data(data_dup)  # Metadata in our phyloseq object
scale_otu <- otu_table(noscale_merge)  # OTU table in our phyloseq object
scale_tax <- tax_table(noscale_merge)  # Taxonomy Table in our phyloseq object
raw_merged <- merge_phyloseq(scale_otu, scale_tax, data_dup) #####  THIS IS OUR RAW MERGED SAMPLES PHYLOSEQ OBJECT.

##  Sample read counts with merging samples WITHOUT SCALING!!!! 
# Histogram of RAW sample read counts
mean_plot <- ggplot(data.frame(sum=sample_sums(noscale_merge)),aes(sum)) + ylab("Number of Sequences per Sample") +
  geom_histogram(colour="black",fill="violetred", binwidth = 500)  + xlab("Total Sequences") + 
  ggtitle(expression(atop(bold("Mean Samples Without Scaling the Reads"), atop("Binwidth = 500 Sequences", ""))))
```

```{r Mean and Rounded Samples}
### Take the average for samples that have a replicate
round_mean_merge <- merge_samples_mean(bact_samples, group = "dups", round = "round")  # Here we calculate the "r" mean between the replicate samples 
round_mean_merge <- prune_taxa(taxa_sums(round_mean_merge) > 0, round_mean_merge)

#######  The above functions mess up the metadata - let's fix it!
data_dup_round <- read.table("~/Final_PAFL_Trophicstate/raw_data/duplicate_metadata.txt", header = TRUE, sep = "\t")
row.names(data_dup_round) <- data_dup_round$names
data_dup_round$quadrant <- factor(data_dup_round$quadrant,levels = c("Free Epilimnion", "Free Mixed",  "Free Hypolimnion", "Particle Epilimnion", "Particle Mixed", "Particle Hypolimnion"))
data_dup_round <- sample_data(data_dup_round)  # Metadata in our phyloseq object
scale_otu <- otu_table(round_mean_merge)  # OTU table in our phyloseq object
scale_tax <- tax_table(round_mean_merge)  # Taxonomy Table in our phyloseq object
round_mean_merge <- merge_phyloseq(scale_otu, scale_tax, data_dup_round) #####  THIS IS OUR RAW MERGED SAMPLES PHYLOSEQ OBJECT.

##  Sample read counts with merging samples WITHOUT SCALING!!!! 
# Histogram of RAW sample read counts
mean_round_plot <- ggplot(data.frame(sum=sample_sums(round_mean_merge)),aes(sum)) + ylab("Number of Sequences per Sample") +
  geom_histogram(colour="black",fill="tomato", binwidth = 500)  + xlab("Total Sequences") + 
  ggtitle(expression(atop(bold("Mean and 'R' rounded Samples Without Scaling the Reads"), atop("Binwidth = 500 Sequences", ""))))
```

```{r Mean and Floored Samples, fig.width = 15, fig.height = 6}
################################################################
### Take the average for samples that have a replicate
floor_mean_merge <- merge_samples_mean(bact_samples, group = "dups", round = "floor")  # Calculate the mean and floor the values
floor_mean_merge <- prune_taxa(taxa_sums(floor_mean_merge) > 0, floor_mean_merge)

#######  The above functions mess up the metadata - let's fix it!
data_dup_floor <- read.table("~/Final_PAFL_Trophicstate/raw_data/duplicate_metadata.txt", header = TRUE, sep = "\t")
row.names(data_dup_floor) <- data_dup_floor$names
data_dup_floor$quadrant <- factor(data_dup_floor$quadrant,levels = c("Free Epilimnion", "Free Mixed",  "Free Hypolimnion", "Particle Epilimnion", "Particle Mixed", "Particle Hypolimnion"))
data_dup_floor <- sample_data(data_dup_floor)  # Metadata in our phyloseq object
scale_otu <- otu_table(floor_mean_merge)  # OTU table in our phyloseq object
scale_tax <- tax_table(floor_mean_merge)  # Taxonomy Table in our phyloseq object
floor_mean_merge <- merge_phyloseq(scale_otu, scale_tax, data_dup_floor) #####  THIS IS OUR RAW MERGED SAMPLES PHYLOSEQ OBJECT.

# Histogram of sample read counts
mean_floor_plot <- ggplot(data.frame(sum=sample_sums(floor_mean_merge)),aes(sum)) + ylab("Number of Sequences per Sample") +
  geom_histogram(colour="black",fill="darkorange", binwidth = 500)  + xlab("Total Sequences") + 
  ggtitle(expression(atop(bold("Mean and Floored Samples Without Scaling the Reads"), atop("Binwidth = 500 Sequences", ""))))
```



```{r Mean and True Rounding of Samples, fig.height = 12, fig.width = 12}
################################################################
### Take the average for samples that have a replicate
matround_mean_merge <- merge_samples_mean(bact_samples, group = "dups", round = "matround")  # Calculate the "true mean"
matround_mean_merge <- prune_taxa(taxa_sums(matround_mean_merge) > 0, matround_mean_merge)

#######  The above functions mess up the metadata - let's fix it!
data_dup_matround <- read.table("~/Final_PAFL_Trophicstate/raw_data/duplicate_metadata.txt", header = TRUE, sep = "\t")
row.names(data_dup_matround) <- data_dup_matround$names
data_dup_matround$quadrant <- factor(data_dup_matround$quadrant,levels = c("Free Epilimnion", "Free Mixed",  "Free Hypolimnion", "Particle Epilimnion", "Particle Mixed", "Particle Hypolimnion"))
data_dup_matround <- sample_data(data_dup_matround)  # Metadata in our phyloseq object
scale_otu <- otu_table(matround_mean_merge)  # OTU table in our phyloseq object
scale_tax <- tax_table(matround_mean_merge)  # Taxonomy Table in our phyloseq object
matround_mean_merge <- merge_phyloseq(scale_otu, scale_tax, data_dup_matround) #####  THIS IS OUR RAW MERGED SAMPLES PHYLOSEQ OBJECT.

# Histogram of RAW sample read counts
mean_matround_plot <- ggplot(data.frame(sum=sample_sums(matround_mean_merge)),aes(sum)) + ylab("Number of Sequences per Sample") +
  geom_histogram(colour="black",fill="orangered3", binwidth = 500)  + xlab("Total Sequences") + 
  ggtitle(expression(atop(bold("Mean and 'True' Rounding Samples Without Scaling the Reads"), atop("Binwidth = 500 Sequences", ""))))

multiplot(mean_plot, mean_round_plot, mean_floor_plot, mean_matround_plot, cols = 2)
```



## Influence of Merging Samples and Scaling the Reads 
```{r scale reads by rounding and flooring}
### Now let's scale our read counts from our MERGED RAW data
scaled_merged_round <- scale_reads(physeq = raw_merged, n = min(sample_sums(raw_merged)), round = "round")

# Histogram of sample read counts
mean_scaled_round_plot <- ggplot(data.frame(sum=sample_sums(scaled_merged_round)),aes(sum)) + ylab("Number of Sequences per Sample") +
  geom_histogram(colour="black",fill="plum2", binwidth = 20)  + xlab("Total Sequences") + 
  ggtitle(expression(atop(bold("Mean Samples with Scaling (and 'r' rounding) the Reads"), atop("Binwidth = 20"), ""))) 

# Scaled with a "true" rounding function 
scaled_merged_matround <- scale_reads(physeq = raw_merged, n = min(sample_sums(raw_merged)), round = "matround")
# Histogram of sample read counts
mean_scaled_matround_plot <- ggplot(data.frame(sum=sample_sums(scaled_merged_matround)),aes(sum)) + ylab("Number of Sequences per Sample") +
  geom_histogram(colour="black",fill="plum4", binwidth = 20)  + xlab("Total Sequences") + 
  ggtitle(expression(atop(bold("Mean Samples with Scaling (and 'true' rounding) the Reads"), atop("Binwidth = 20"), ""))) 


## Now let's scale our read counts from our MERGED RAW data
scaled_merged_floor <- scale_reads(physeq = raw_merged, n = min(sample_sums(raw_merged)), round = "floor")

# Histogram of sample read counts 
mean_scaled_floor_plot <- ggplot(data.frame(sum=sample_sums(scaled_merged_floor)),aes(sum)) + ylab("Number of Sequences per Sample") +
  geom_histogram(colour="black",fill="purple", binwidth = 20)  + xlab("Total Sequences") + 
  ggtitle(expression(atop(bold("Mean Samples with Scaling (and flooring) the Reads"), atop("Binwidth = 20"), ""))) 
```



```{r sum-scale }
### Now let's 1. sum between replicates.  

# Step 1.  Sum the reads 
sum_reps <- merge_samples(x = bact_samples, group = "dups", fun = "sum") # Sum between replicate samples
sum_reps <- prune_taxa(taxa_sums(sum_reps) > 0, sum_reps) # Remove any OTUs that are 0

# The above function ruins the sample data :/  
data_dup_sum_reps <- read.table("~/Final_PAFL_Trophicstate/raw_data/duplicate_metadata.txt", header = TRUE, sep = "\t")
row.names(data_dup_sum_reps) <- data_dup_sum_reps$names
data_dup_sum_reps$quadrant <- factor(data_dup_sum_reps$quadrant,levels = c("Free Epilimnion", "Free Mixed",  "Free Hypolimnion", "Particle Epilimnion", "Particle Mixed", "Particle Hypolimnion"))
# Add a column of Total Sequence sums 
TotalSeqs_sum_reps <- data.frame(rowSums(otu_table(sum_reps)))
TotalSeqs_sum_reps$names <- as.factor(row.names(TotalSeqs_sum_reps))
colnames(TotalSeqs_sum_reps)[1] <- "TotalSeqs_Summed"
data_dup_sum_reps<- left_join(data_dup_sum_reps, TotalSeqs_sum_reps, by = "names")
row.names(data_dup_sum_reps) <- data_dup_sum_reps$names
data_dup_sum_reps <- sample_data(data_dup_sum_reps)  # Metadata in our phyloseq object
scale_otu <- otu_table(sum_reps)  # OTU table in our phyloseq object
scale_tax <- tax_table(sum_reps)  # Taxonomy Table in our phyloseq object
sum_reps <- merge_phyloseq(scale_otu, scale_tax, data_dup_sum_reps) #####  THIS IS OUR RAW MERGED SAMPLES PHYLOSEQ OBJECT.

# Step 3:  Scale the reads by flooring
sum_scale_floor <- scale_reads(physeq = sum_reps, n = min(sample_sums(sum_reps)), round = "floor")

##  Histogram of Sample Read Counts 
sum_scale_floor_plot <- ggplot(data.frame(sum=sample_sums(sum_scale_floor)),aes(sum)) + ylab("Number of Sequences per Sample") +
  geom_histogram(colour="black",fill="thistle1", binwidth = 20)  + xlab("Total Sequences") + 
  ggtitle(expression(atop(bold("Sum & Scale (by flooring) the Reads"), atop("Binwidth = 20"), ""))) 

# Step 3:  Scale the reads by rounding
sum_scale_round <- scale_reads(physeq = sum_reps, n = min(sample_sums(sum_reps)), round = "round")

##  Histogram of Sample Read Counts 
sum_scale_round_plot <- ggplot(data.frame(sum=sample_sums(sum_scale_round)),aes(sum)) + ylab("Number of Sequences per Sample") +
  geom_histogram(colour="black",fill="thistle1", binwidth = 20)  + xlab("Total Sequences") + 
  ggtitle(expression(atop(bold("Sum & Scale (by 'R' rounding) the Reads"), atop("Binwidth = 20"), ""))) 

# Step 3:  Scale the reads 
sum_scale_matround <- scale_reads(physeq = sum_reps, n = min(sample_sums(sum_reps)), round = "matround")


data_dup_sum_scale_matround <- read.table("~/Final_PAFL_Trophicstate/raw_data/duplicate_metadata.txt", header = TRUE, sep = "\t")
row.names(data_dup_sum_scale_matround) <- data_dup_sum_scale_matround$names
data_dup_sum_scale_matround$quadrant <- factor(data_dup_sum_scale_matround$quadrant,levels = c("Free Epilimnion", "Free Mixed",  "Free Hypolimnion", "Particle Epilimnion", "Particle Mixed", "Particle Hypolimnion"))
# Add a column of Total Sequence sums 
TotalSeqs_sum_reps <- data.frame(rowSums(otu_table(sum_reps)))
TotalSeqs_sum_reps$names <- as.factor(row.names(TotalSeqs_sum_reps))
colnames(TotalSeqs_sum_reps)[1] <- "TotalSeqs_Summed"
data_dup_sum_scale_matround_join<- left_join(data_dup_sum_scale_matround, TotalSeqs_sum_reps, by = "names") 

TotalSeqs_sum_scale_matround <- data.frame(rowSums(otu_table(sum_scale_matround)))
TotalSeqs_sum_scale_matround$names <- as.factor(row.names(TotalSeqs_sum_scale_matround))
colnames(TotalSeqs_sum_scale_matround)[1] <- "TotalSeqs_Scaled"
data_dup_sum_scale_matround_join<- left_join(data_dup_sum_scale_matround_join, TotalSeqs_sum_scale_matround, by = "names") 
row.names(data_dup_sum_scale_matround_join) <- data_dup_sum_scale_matround_join$names

data_dup_sum_scale_matround_join <- sample_data(data_dup_sum_scale_matround_join)  # Metadata in our phyloseq object
sum_scale_matround_otu <- otu_table(sum_scale_matround)  # OTU table in our phyloseq object
sum_scale_matround_tax <- tax_table(sum_scale_matround)  # Taxonomy Table in our phyloseq object
sum_scale_matround <- merge_phyloseq(sum_scale_matround_otu, sum_scale_matround_tax, data_dup_sum_scale_matround_join) #####  THIS IS OUR RAW MERGED SAMPLES PHYLOSEQ OBJECT.


##  Histogram of Sample Read Counts 
sum_scale_matround_plot <- ggplot(data.frame(sum=sample_sums(sum_scale_matround)),aes(sum)) + ylab("Number of Sequences per Sample") +
  geom_histogram(colour="black",fill="thistle1", binwidth = 20)  + xlab("Total Sequences") + 
  ggtitle(expression(atop(bold("Sum & Scale (by 'True' rounding) the Reads"), atop("Binwidth = 20"), ""))) 
```


```{r Sequencing Depth Table, results = 'asis', fig.width = 15, fig.height = 6}
manipulations <- c("Raw Samples", "Mean Samples Without Scaling", "Mean and 'R' Rounded Samples Without Scaling", "Mean and 'True' Rounded Samples Without Scaling", "Mean and Floored Samples Without Scaling", "Mean Samples with Scaling (and flooring) the Reads", "Mean Samples with Scaling ('R' rounding) the Reads", "Mean Samples with Scaling ('True' rounding) the Reads", "Sum & Scale (by flooring) the Reads", "Sum & Scale (by 'R' rounding) the Reads", "Sum & Scale (by 'True' rounding) the Reads")

mins <- c(min(sample_sums(bact_samples)), min(sample_sums(raw_merged)),  min(sample_sums(round_mean_merge)), min(sample_sums(matround_mean_merge)),min(sample_sums(floor_mean_merge)), min(sample_sums(scaled_merged_floor)), min(sample_sums(scaled_merged_round)), min(sample_sums(scaled_merged_matround)), min(sample_sums(sum_scale_floor)), min(sample_sums(sum_scale_round)), min(sample_sums(sum_scale_matround)))

means <- c(round(mean(sample_sums(bact_samples)), digits = 2), round(mean(sample_sums(raw_merged)), digits = 2), round(mean(sample_sums(round_mean_merge)), digits = 2),round(mean(sample_sums(matround_mean_merge)), digits = 2), round(mean(sample_sums(floor_mean_merge)), digits = 2), round(mean(sample_sums(scaled_merged_floor)), digits = 2), round(mean(sample_sums(scaled_merged_round)), digits = 2), round(mean(sample_sums(scaled_merged_matround)), digits = 2), round(mean(sample_sums(sum_scale_floor)), digits = 2), round(mean(sample_sums(sum_scale_round)), digits = 2), round(mean(sample_sums(sum_scale_matround)), digits = 2))

medians <- c(median(sample_sums(bact_samples)), median(sample_sums(raw_merged)), median(sample_sums(round_mean_merge)), median(sample_sums(matround_mean_merge)), median(sample_sums(floor_mean_merge)), median(sample_sums(scaled_merged_floor)),median(sample_sums(scaled_merged_round)), median(sample_sums(scaled_merged_matround)), median(sample_sums(sum_scale_floor)), median(sample_sums(sum_scale_round)), median(sample_sums(sum_scale_matround)))

maxs <- c(max(sample_sums(bact_samples)), max(sample_sums(raw_merged)), max(sample_sums(round_mean_merge)), max(sample_sums(matround_mean_merge)), max(sample_sums(floor_mean_merge)), max(sample_sums(scaled_merged_floor)), max(sample_sums(scaled_merged_round)), max(sample_sums(scaled_merged_matround)), max(sample_sums(sum_scale_floor)), max(sample_sums(sum_scale_round)), max(sample_sums(sum_scale_matround)))

ranges <- c(max(sample_sums(bact_samples)) - min(sample_sums(bact_samples)), max(sample_sums(raw_merged)) - min(sample_sums(raw_merged)), max(sample_sums(round_mean_merge)) - min(sample_sums(round_mean_merge)), max(sample_sums(matround_mean_merge)) - min(sample_sums(matround_mean_merge)), max(sample_sums(floor_mean_merge)) - min(sample_sums(floor_mean_merge)), max(sample_sums(scaled_merged_floor)) - min(sample_sums(scaled_merged_floor)), max(sample_sums(scaled_merged_round)) - min(sample_sums(scaled_merged_round)), max(sample_sums(scaled_merged_matround)) - min(sample_sums(scaled_merged_matround)), max(sample_sums(sum_scale_floor)) - min(sample_sums(sum_scale_floor)), max(sample_sums(sum_scale_round)) - min(sample_sums(sum_scale_round)), max(sample_sums(sum_scale_matround)) - min(sample_sums(sum_scale_matround)))

num_otus <- c(nrow(otu_table(bact_samples)), nrow(otu_table(raw_merged)), nrow(otu_table(round_mean_merge)), nrow(otu_table(matround_mean_merge)), nrow(otu_table(floor_mean_merge)), nrow(otu_table(scaled_merged_floor)), nrow(otu_table(scaled_merged_round)), nrow(otu_table(scaled_merged_matround)),  ncol(otu_table(sum_scale_floor)), ncol(otu_table(sum_scale_round)), ncol(otu_table(sum_scale_matround)))

# Make the data frame 
seq_depth <- data.frame(matrix(ncol = 0, nrow = 11))
row.names(seq_depth) <- manipulations
seq_depth$Minimum_Seqs <- mins
seq_depth$Mean_Seqs <- means
seq_depth$Median_Seqs <- medians
seq_depth$Maximum_Seqs <- maxs
seq_depth$Range_Seqs <- ranges
seq_depth$Number_of_OTUs <- num_otus
```

## Meaning between replicates without scaling
```{r}
###  Time to make the pander output of our table!  
panderOptions("digits", 1) # This will set the values to numbers and then will round to the whole number
set.alignment('center', row.names = 'right') # This will align all cells with "center" alignment and the row.names with "right" alignment
pander(seq_depth[1:5,], caption="Table A:  Simple statistics on the sequencing depth while merging replicates WITHOUT scaling.")

```

## **Mean** between replicates and then scale the sample read counts
```{r mean scale stats, fig.width = 15, fig.height = 6}
multiplot(mean_scaled_floor_plot, mean_scaled_round_plot, mean_scaled_matround_plot,cols = 3)

panderOptions("digits", 1) # This will set the values to numbers and then will round to the whole number
set.alignment('center', row.names = 'right') # This will align all cells with "center" alignment and the row.names with "right" alignment
pander(seq_depth[6:8,], caption="Table A:  Simple statistics on the sequencing depth while merging replicates WITH scaling.")
```

## **Sum** between replicates and then scale the sample read counts
```{r sum-scaled stats, fig.width = 15, fig.height = 6}
multiplot(sum_scale_floor_plot, sum_scale_round_plot, sum_scale_matround_plot,cols = 3)

panderOptions("digits", 1) # This will set the values to numbers and then will round to the whole number
set.alignment('center', row.names = 'right') # This will align all cells with "center" alignment and the row.names with "right" alignment
pander(seq_depth[9:11,], caption="Table A:  Simple statistics on the sequencing depth while SUMMING replicates WITH scaling.")
```


```{r Create phyloseq object}
###  Time to create our phyloseq object with the merged and scaled sample reads.
merged_final <- scaled_merged_round

########## ADD THE PROTEOBACTERIA TO THE PHYLA
phy <- data.frame(tax_table(merged_final))
Phylum <- as.character(phy$Phylum)
Class <- as.character(phy$Class)

for  (i in 1:length(Phylum)){ 
  if (Phylum[i] == "Proteobacteria"){
    Phylum[i] <- Class[i]
  } 
}

phy$Phylum <- Phylum
t <- tax_table(as.matrix(phy))

tax_table(merged_final) <- t

# Our phyloseq object!
#merged_final 

## The same object without the 2 wintergreen "hypolimnion" samples
nowin_final_nov2 <- subset_samples(merged_final, names != "WINH" & names != "WINH3um")
nowin_final_nov2 <- prune_taxa(taxa_sums(nowin_final_nov2) > 0, nowin_final_nov2)

```




```{r ordinate!}
####################################################  ORDINATIONS  ####################################################  Working up to Figure 3
####################################################  ORDINATIONS  ####################################################  Working up to FIgure 3
####################################################  ORDINATIONS  ####################################################  Working up to Figure 3
### Clustering 
### Get rid of the Wintergreen HYPOLIMNION Samples
nowin_merged <- subset_samples(merged_final, names != "WINH" & names != "WINH3um")
nowin_merged <- prune_taxa(taxa_sums(nowin_merged) > 0, nowin_merged)
nowinOTU <- otu_table(nowin_merged)
#weighted
norm_bray <- vegdist(nowinOTU, method = "bray", binary = FALSE)  # calculates the Bray-Curtis Distances
nowinOTU_df <- data.frame(otu_table(nowin_merged))  
norm_soren <- vegdist(nowinOTU_df, method = "bray", binary = TRUE)  # SORENSEN INDEX




```
